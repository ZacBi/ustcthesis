% !TeX root = ../main.tex

\chapter{相关知识与背景引导}

\section{上下文无关语法}

上下文无关语法起源于语言学，用于描述自然语言中语句和单词的结构，由语言学家诺姆·乔姆斯基发明。
在计算机科学的早期应用中，语法被用来描述编程语言的结构。
之后常作为可扩展标记语言（XML，Extensible Markup Language）的一个重要部分而被广泛应用，称为文档类型定义\cite{hopcroft2001introduction}。
在语言学中，一些作者使用术语“短语结构语法”来指代上下文无关语法，因此短语结构语法不同于依赖语法。在计算机科学中，上下文无关语法的一种通用符号表示是Backus–Naur范式(BNF)。

上下文无关语法在形式语言理论中是一种形式语法，本质上是一组产生式规则，用以描述给定形式语言中所有可能的字符串。其产生式规则形如：A \rightarrow $\alpha$。
其中A为非终止符，$\alpha$则是由一组终止符，非终止符或空串组成的符号串。
它与上下文相关语法的区别主要在于任何情况下左侧的单个非终止符都可以替换为右侧的符号串，即无论非终止符的上下文是什么，它的产生式规则可以被应用。
产生式规则的应用就是进行简单的替换。例如这一条规则: $\displaystyle \langle {\text{Stmt}}\rangle \to \langle {\text{Id}}\rangle =\langle {\text{Expr}}\rangle$，
可以用$\displaystyle \langle {\text{Stmt}}\rangle$ 取代 $\langle {\text{Id}}\rangle =\langle {\text{Expr}}\rangle$。

上下文无关语法中给定的非终止符号可以有多个替换规则。语法生成的语言是所有终止符号字符串的集合，这些字符串可以通过重复的规则应用程序从某个特定的非终止符号（又称为起始符号）派生出来。
非终止符符号在派生过程中使用，但不会出现在其最终结果字符串中。上下文无关语言（CFL，Context-Free Language）可由上下文无关语法生成，不同的上下文无关语法可以生成相同的上下文无关语言。

\subsection{概率无关上下文语法}

模拟符号串的语法理论起源于计算语言学中理解自然语言结构的工作\cite{chomsky1956three,chomsky1959certain,lees1957syntactic}。
概率上下文无关文法（PCFG，Probabilistic Context-Free Grammar）在计算语言学中引入近40年后被应用于RNA结构的概率建模等领域\cite{sakakibara1994stochastic}。

概率上下文无关语法对于上下文无关语法的扩展在于为每一个产生式赋予了一个概率值，其可以表示为 $\displaystyle A \rightarrow \beta [p]$, 这里p表示给定的非终止符A展开到序列$\beta$的概率，
因此，如果我们考虑非终止符的所有可能展开，它们的概率之和必须是1：$\displaystyle \sum_\beta P(A \rightarrow \beta) \equal 1$。
如果某个语言中所有语句的概率之和等于1，则称该语言的概率上下文无关语法是一致的。某些类型的递归产生式会导致某些语句的无限循环派生，从而导致语法不一致。
例如，一条为$\displaystyle S \rightarrow S$且概率为1的规则将由于永远不会终止的推导而导致概率质量损失\cite{1672339}。

PCFG可用于估计关于语句及其解析树的许多有用概率，包括特定解析树的概率（用于消歧）和语句或语句片段的概率（用于语言建模）。
PCFG会为输入语句的每个解析树（即每个派生）分配一个概率，该属性在消歧中很有用。对于一个语句S的某个解析树T，其概率被定义为该解析树中n条产生式$\displaystyle LHS_i \rightarrow RHS_i$的概率乘积,
其中LHS表示左手端符号，RHS表示右手端符号，则解析树T和语句S的联合概率可以表示为：$\displaystyle P(T, S) = \prod_{i \equal 1}^{n} P(RHS_i|LHS_i)$，
又因为该解析树T必然生成语句S，即$\displaystyle P(S|T) \equal 1$，所以有$\displaystyle P(T, S) \equal P(T)P(S|T) \equal P(T)$, 最终解析树的概率将被计算出来。

概率上下文无关语法的概率学习一般有两种方式。一种为使用成熟的解析树库，即存放已经被解析的语句构成的语料集，比较典型的是Penn Treebank库\cite{Penn-Treebank}，这是有Linguistic Data
Consortium分发的一个包含英语，中文以及其他语言的语料集。给定一个解析树库，我们可以通过计算扩展发生的次数，然后进行归一化，来计算非终止符的派生概率，这也是朴素贝叶斯模型的思想。
其公式为$\displaystyle P(\alpha \rightarrow \beta) \equal \frac{\textup{Count}(\alpha \rightarrow \beta)}{\sum_{\gamma}\textup{Count}(\alpha \rightarrow \gamma)} \equal \frac{\textup{Count}(\alpha \rightarrow \beta)}{\textup{Count}(\alpha)}$。

另一种方式针对不存在可用解析树库的情况下，可以首先使用非概率的解析器，从需要我们分析的语料库中计算所有可能产生式的计数，然后通过朴素贝叶斯模型获取每个产生式的概率。

但现实场景中许多语句都是具有歧义性的，即一个语句会具有多个语法解析树，导致难以判断在哪个语法分析中计算产生式的概率。
所以我们需要为一个语句的每个语法解析树保留一个单独的计数，并根据它出现在语法分析中的概率对这些语法解析树的计数进行加权。
但是为了获取语法解析树的原始概率，我们又需要一个已有概率解析器，造成了典型的循环论证问题。
对于概率上下文无关语法中的这种问题的直觉算法是，通过从具有相同规则概率的解析器开始解析句子，计算每个解析树的概率，
再使用这些概率加权每个产生式计数，重新估计规则概率，如此反复直到概率收敛于某一数值为止。计算这一问题的标准算法被称为内-外算法，是隐马尔可夫模型中的前-后算法的一种衍生算法\cite{1979Trainable}。

% 概率无关上下文语法扩展上下文无关语法的方式类似于隐马尔可夫模型扩展正则表达式语法的方式，其每个产生式都具有相应的概率，语法中的任意非终止符最终推导出终止符串的概率是该推导过程中使用到的所有产生式概率的乘积。
% 某些情况下，产生式的概率可以视为数学模型的参数，这些参数可通过机器学习的方式预估计算，但概率语法的有效性受到其训练数据集上下文的约束。
% 为了设计出高效的概率无关上下文语法，则必须权衡可伸缩性和通用性等因素，因此必须解决语法歧义问题的同时还需满足语法分析算法中的时间和内存需求。

% 概率无关上下文语法中有三个比较重要的概念，分别是推导、解析和解析树。
% 推导是从语法中的非终止符递归生成字符串; 解析使用自动机查找有效的推导; 解析树则将语法与输入文本序列进行对齐。
% 概率无关上下文语法实现的一个示例是下推自动机\cite{sippl1999biological}，该算法以类似堆栈的方式从左到右暴力解析语法非终止符，而后来的Cocke–Younger–Kasami（CYK）算法的变体提供了比下推自动机更有效的语法分析替代方法。
% 概率无关上下文语法实现的另一个示例是Stanford统计解析器\cite{klein2003accurate}，它使用TreeBank语料集进行训练。



\subsection{CYK算法}

在计算机科学中，Cocke–Younger–Kasami算法（也称为CYK，或CKY）是Itiroo Sakai\cite{mey1965international}于1961年发布的上下文无关语法解析算法，
它采用自下而上的解析和动态规划。
CYK的标准版本仅对以乔姆斯基范式（CNF，Chomsky Normal Form）给出的上下文无关语法进行操作。但是，任何上下文无关语法都可以（在约定之后）转换为表示相同语言的乔姆斯基范式语法。

CYK算法的重要性源于它在某些情况下的高效性。使用大O表示法，CYK最坏情况下的运行时间是$\displaystyle \mathcal{O} (n^{3} \cdot |G|)$，其中n是解析语句的长度，|G|是乔姆斯基范式语法G的大小.
这使得它在最坏情况下的渐近复杂度方面成为最有效的解析算法之一，尽管在许多实际场景中存在其他算法具有更好的平均运行时间\cite{sipser1997context}。
CYK算法可见算法~\ref{algo:tree_construction}，其中CYK将以概率上下文无关语法与某个语句作为输入，得到该语句具有最大概率的一棵解析树以及该解析树的概率。

\begin{algorithm}[h]
    \SetAlgoVlined
    \KwData{概率上下文无关语法及可由该语法生成的语句}
    \KwResult{具有最大概率的一棵解析树以及该解析树的概率}
    \BlankLine

    initialization\;
    \For{\text{j \leftarrow 1 \KwTo \textup{LENGTH}(string)}} {
        \ForAll{ $\left\{ A | A \rightarrow string[j] \in grammar \right\}$}{
            \tcp{table为动态规划表，P(x) 为产生式x的概率}
            $table[j-1, j, A] \leftarrow P(A \rightarrow string[j])$\;
        }

        \For{\text{i \leftarrow j - 2 \KwTo 0}}{
            \For{\text{k \leftarrow i + 1 \KwTo j - 1}}{
                \ForAll{$\left\{A | A \rightarrow BC \in grammar \right\}$ {\bf and} $table[i,k,B] \ge 0$ {\bf and} $table[k,j,c] \ge 0$}{
                    \If{$(table[i,j,A] \less P(A \rightarrow BC) \times table[i,k,B] \times table[k,j,c])$}{
                        $table[i,j,A] \leftarrow  P(A \rightarrow BC) \times table[i,k,B] \times table[k,j,c]$\;
                        \tcp{back为动态规划回溯表}
                        $back[i,j,A] \leftarrow \left\{k,B,C\right\}$\;
                    }
                }
            }
        }
    }
    \Return{\text{\textup{BUILD\_TREE}(back[1, \textup{LENGTH}(string), S], table[1, \textup{LENGTH}(string), S])}}
    \caption{CYK算法}
    \label{algo:tree_construction}
\end{algorithm}


\section{SciKit-Learn框架}

Scikit-Learn（前身为scikits.learn，也称为sklearn）是一个用于Python编程语言的自由软件机器学习库\cite{pedregosa2011scikit}，是一个单独开发和分发的SciPy\cite{kramer2016scikit}第三方扩展。
2010年，Fabian Pedregosa、Gael Varoquaux、Alexandre Gramfort和Vincent Michel领导了该项目，
并于2010年2月1日首次公开发布了各种SciKit。Scikit-Learn在2012年11月被描述为“维护良好且受欢迎”\cite{bressert2012scipy}。
Scikit-Learn是GitHub\cite{gonzalez2020state}上最受欢迎的机器学习库之一。它具有各种分类、回归和聚类算法，并且设计用于与Python数字和科学库NumPy和SciPy进行互操作。
Scikit-Learn主要是用Python编写的，广泛使用NumPy进行高性能线性代数和数组操作。此外还用Cython编写了一些核心算法以提高性能。
Scikit-Learn与许多其他Python库很好地集成，例如用于绘图的Matplotlib和plotly、用于阵列矢量化的NumPy、Pandas dataframes、SciPy等。

\subsection{朴素贝叶斯模型}

SciKit-Learn框架中封装了大量的分类回归和聚类算法，其中就包括朴素贝叶斯模型。在统计学中，朴素贝叶斯分类器是一个简单的“概率分类器”家族\cite{larranaga2013review}，基于贝叶斯定理和特征之间的强独立性假设。
它们是最简单的贝叶斯网络模型之一，但与核密度估计相结合可以达到更高的精度水平\cite{piryonesi2020role}。

朴素贝叶斯分类器具有高度的可伸缩性，在学习问题中需要在变量（特征/预测）数量上具有线性的多个参数。
最大似然训练可以通过评估一个封闭形式的表达式来完成\cite{russell2002artificial}，它需要线性时间而不是像许多其他类型的分类器那样通过昂贵的迭代近似来完成。

朴素贝叶斯是一种构造分类器的简单技术：将类标签用特征值向量表示并分配给问题实例的模型，其中类标签是从某个目标问题的有限集合中提取的。
训练此类分类器的算法并不唯一，但都具有一个共同的假设：所有朴素贝叶斯分类器都假定在给定类变量的前提下，所需求得的特定特征的值独立于任何其他特征的值。

尽管朴素贝叶斯分类器的设计和假设显然过于简单，但它们在许多复杂的现实环境中都能很好地工作。
直达2004年，对贝叶斯分类问题的分析表明，朴素贝叶斯分类器的效果明显不可信有着合理的理论原因。
然而，2006年与其他分类算法的综合研究比较表明，贝叶斯分类优于其他方法，比如茂密的树木或随机的森林。
朴素贝叶斯的最大的优点是，它只需要少量的训练数据来估计分类所需的参数\cite{10.1145/1143844.1143865}。

\section{MongoDB数据库}

MongoDB是由MongoDB Inc.开发的面向文档的跨平台数据库应用，它被归类为非关系型(NoSQL，Not-only SQL)数据库应用，并使用带有可选模式的类似JSON的文档。
MongoDB字段可能因文档而异，即无需向系统声明文档的结构，因为其内部存储的文档是自描述的，
必要情况下也可以使用模式验证对每个集合实施强制的数据治理控制和字段校验。

MongoDB和MySQL具有很大的不同\cite{Győrödi2015comparative}，MySQL是Oracle公司开发的典型关系型数据库管理系统（RDBMS）。
与其他关系型数据库系统一样，MySQL将数据存储在表中，并使用结构化查询语言（SQL）访问数据库。
当MySQL开发人员需要访问应用程序中的数据时，他们会将多个表中的数据合并到一个称为连接的过程中。
在MySQL中可以预定义数据库模式并设置规则来管理表中字段之间的关系。

随着MongoDB文档自然地映射到现代的面向对象编程语言，开发过程被简化。
使用MongoDB可以简化将代码中的对象转换为关系表的复杂对象关系映射层。
MongoDB灵活的数据模型还意味着软件应用的数据库模式可以随着业务需求而发展，
MySQL僵化的关系结构则增加了应用程序的开销，并降低了开发人员的开发速度，因为他们必须使代码中的对象适应关系结构。

MongoDB还可以在多个分布式数据中心内部和跨多个分布式数据中心进行扩展，从而提供以前MySQL等关系型数据库无法实现的新级别的可用性和可扩展性。
随着内部整体系统的部署在数据量和吞吐量方面的增长，MongoDB可以轻松扩展，无需停机，也无需更改应用程序。
相反，使用MySQL实现规模通常需要大量定制工程工作。各种规模的组织都在采用MongoDB，尤其是作为云数据库，因为它使它们能够更快地构建应用程序，处理高度多样化的数据类型，并更高效地管理大规模应用程序。


\section{本章小结}

本章最初介绍了中文时间表达式信息识别模块的核心算法，CYK算法及其诞生的背景：上下文无关语法和概率上下文无关语法。
紧接着介绍了中文时间表达式信息解析模块设计到的关键技术，包括SciKit-Learn框架封装的朴素贝叶斯选择器，以解决时间语义归一化为结构化时间对象的问题。
最后介绍了MongoDB这样一款非关系型数据库，以此解决大量的文本储存问题。这些技术的有机结合，是中文时间表达式信息抽取系统的良好基础。
在了解相关的技术之后，第三章将详细阐述该中文时间表达式信息抽取系统的需求分析。
